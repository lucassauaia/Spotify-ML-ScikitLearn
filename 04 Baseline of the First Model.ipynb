{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Baseline ðŸ§µ\n",
    "\n",
    "> A baseline is the result of a very basic model/solution. You usually create a baseline and then try to do more complex solutions to get a better result. If you can get a better score than the baseline, that's good.\n",
    "\n",
    "I started by dividing the data into training and validation (X - predictor variables, y - objective variable) and then used `StratifiedKFold`, which separates the data for cross validation while preserving the percentage of samples in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before that, we need to restore the DataFrame from the Dataset Division point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lucas\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucas\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lucas\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lucas\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lucas\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Python libraries\n",
    "!pip install pandas numpy seaborn matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_21944\\1152092983.py:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(strip_whitespaces)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 113999 entries, 0 to 113999\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Unnamed: 0        113999 non-null  int64  \n",
      " 1   duration_ms       113999 non-null  int64  \n",
      " 2   danceability      113999 non-null  float64\n",
      " 3   energy            113999 non-null  float64\n",
      " 4   key               113999 non-null  int64  \n",
      " 5   loudness          113999 non-null  float64\n",
      " 6   mode              113999 non-null  int64  \n",
      " 7   speechiness       113999 non-null  float64\n",
      " 8   acousticness      113999 non-null  float64\n",
      " 9   instrumentalness  113999 non-null  float64\n",
      " 10  liveness          113999 non-null  float64\n",
      " 11  valence           113999 non-null  float64\n",
      " 12  tempo             113999 non-null  float64\n",
      " 13  time_signature    113999 non-null  int64  \n",
      " 14  pop_class         113999 non-null  int32  \n",
      "dtypes: float64(9), int32(1), int64(5)\n",
      "memory usage: 13.5 MB\n",
      "Dimensions: ((72960, 14), (18239, 14), (72960,), (18239,))\n",
      "\n",
      "Proportion of df_train for class=1: 0.0107\n",
      "\n",
      "Proportion of X_train for class=1: 0.0107\n",
      "Proportion of X_val for class=1: 0.0107\n"
     ]
    }
   ],
   "source": [
    "# Import Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the dataset into a DataFrame\n",
    "df = pd.read_csv(\"asset/dataset.csv\")\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "# Remove null values\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Function to strip whitespaces from object columns\n",
    "def strip_whitespaces(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.strip()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "# Apply the function to all object columns\n",
    "df = df.applymap(strip_whitespaces)\n",
    "# Create popularity classs\n",
    "# Selecting rows where 'popularity' is greater than or equal to 80\n",
    "df[df[\"popularity\"] >= 80]\n",
    "\n",
    "# Defining conditions for the 'pop_class' column\n",
    "conditionlist = [(df[\"popularity\"] >= 80), (df[\"popularity\"] < 80)]\n",
    "\n",
    "# Assigning values based on conditions\n",
    "choicelist = [1, 0]\n",
    "df[\"pop_class\"] = np.select(conditionlist, choicelist, default=\"Not Specified\")\n",
    "\n",
    "# Converting the 'pop_class' column to integer type\n",
    "df[\"pop_class\"] = df[\"pop_class\"].astype(int)\n",
    "\n",
    "# Remove useless columns\n",
    "df = df.drop(columns=[\"popularity\", \"explicit\"])\n",
    "\n",
    "# Keep only quantitative columns that are important for the model\n",
    "\n",
    "df_quantitative = df\n",
    "cols_to_drop = []\n",
    "\n",
    "for column in df:\n",
    "    if df[column].dtype == \"object\":\n",
    "        cols_to_drop.append(column)\n",
    "\n",
    "df_quantitative = df.drop(columns=cols_to_drop)\n",
    "\n",
    "df_quantitative.info()\n",
    "\n",
    "# Normalizing the data, bringing it to the same scale\n",
    "df_quantitative_nm = (df_quantitative - df_quantitative.min()) / (\n",
    "    df_quantitative.max() - df_quantitative.min()\n",
    ")\n",
    "\n",
    "## Split the dataset for Training ðŸ‹ï¸â€â™‚ï¸ and Testing âœ”ï¸\n",
    "df_train, df_test = train_test_split(\n",
    "    df_quantitative_nm, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Visualizing the proportions of the target variable from the Training table\n",
    "df_train[\"pop_class\"].value_counts(normalize=True)\n",
    "\n",
    "# Visualizing the proportions of the target variable from the Testing table\n",
    "df_test[\"pop_class\"].value_counts(normalize=True)\n",
    "\n",
    "## Divide in tables `x` and `y`\n",
    "X = df_train.drop(\"pop_class\", axis=1)\n",
    "y = df_train.pop_class\n",
    "\n",
    "## Separate the data by maintaining the percentage of samples in each class ðŸ”ƒ\n",
    "StratifKfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "## Loop to split in Training ðŸ‹ï¸â€â™‚ï¸ and Validation âœ”ï¸ tables\n",
    "for train_index, val_index in StratifKfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "## Checking the proportions of class 1 in the division ðŸ‘\n",
    "print(f\"Dimensions: {X_train.shape, X_val.shape, y_train.shape, y_val.shape}\\n\")\n",
    "print(\n",
    "    f\"Proportion of df_train for class=1: {round(len(df_train[df_train.pop_class==1]) / df_train.shape[0], 4)}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Proportion of X_train for class=1: {round(len(y_train[y_train==1]) / X_train.shape[0], 4)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Proportion of X_val for class=1: {round(len(y_val[y_val==1]) / X_val.shape[0], 4)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiating the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m logReg \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m logReg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "logReg = LogisticRegression()\n",
    "\n",
    "# Training the model\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training data\n",
    "y_pred_base_train = logReg.predict(X_train)\n",
    "\n",
    "# Predicting on validation data\n",
    "y_pred_base_val = logReg.predict(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
